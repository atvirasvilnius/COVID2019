{"remainingRequest":"C:\\Users\\yz.liu\\Desktop\\Experiment\\COVID2019\\node_modules\\thread-loader\\dist\\cjs.js!C:\\Users\\yz.liu\\Desktop\\Experiment\\COVID2019\\node_modules\\babel-loader\\lib\\index.js!C:\\Users\\yz.liu\\Desktop\\Experiment\\COVID2019\\src\\js\\jenks.js","dependencies":[{"path":"C:\\Users\\yz.liu\\Desktop\\Experiment\\COVID2019\\src\\js\\jenks.js","mtime":1581925828391},{"path":"C:\\Users\\yz.liu\\Desktop\\Experiment\\COVID2019\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1581926356531},{"path":"C:\\Users\\yz.liu\\Desktop\\Experiment\\COVID2019\\node_modules\\thread-loader\\dist\\cjs.js","mtime":1581926357833},{"path":"C:\\Users\\yz.liu\\Desktop\\Experiment\\COVID2019\\node_modules\\babel-loader\\lib\\index.js","mtime":1529635966000}],"contextDependencies":[],"result":["import \"core-js/modules/es6.array.sort\";\n// # [Jenks natural breaks optimization](http://en.wikipedia.org/wiki/Jenks_natural_breaks_optimization)\n//\n// Implementations: [1](http://danieljlewis.org/files/2010/06/Jenks.pdf) (python),\n// [2](https://github.com/vvoovv/djeo-jenks/blob/master/main.js) (buggy),\n// [3](https://github.com/simogeo/geostats/blob/master/lib/geostats.js#L407) (works)\nexport default function jenks(data, n_classes) {\n  // Compute the matrices required for Jenks breaks. These matrices\n  // can be used for any classing of data with `classes <= n_classes`\n  function getMatrices(data, n_classes) {\n    // in the original implementation, these matrices are referred to\n    // as `LC` and `OP`\n    //\n    // * lower_class_limits (LC): optimal lower class limits\n    // * variance_combinations (OP): optimal variance combinations for all classes\n    var lower_class_limits = [],\n        variance_combinations = [],\n        // loop counters\n    i,\n        j,\n        // the variance, as computed at each step in the calculation\n    variance = 0; // Initialize and fill each matrix with zeroes\n\n    for (i = 0; i < data.length + 1; i++) {\n      var tmp1 = [],\n          tmp2 = [];\n\n      for (j = 0; j < n_classes + 1; j++) {\n        tmp1.push(0);\n        tmp2.push(0);\n      }\n\n      lower_class_limits.push(tmp1);\n      variance_combinations.push(tmp2);\n    }\n\n    for (i = 1; i < n_classes + 1; i++) {\n      lower_class_limits[1][i] = 1;\n      variance_combinations[1][i] = 0; // in the original implementation, 9999999 is used but\n      // since Javascript has `Infinity`, we use that.\n\n      for (j = 2; j < data.length + 1; j++) {\n        variance_combinations[j][i] = Infinity;\n      }\n    }\n\n    for (var l = 2; l < data.length + 1; l++) {\n      // `SZ` originally. this is the sum of the values seen thus\n      // far when calculating variance.\n      var sum = 0,\n          // `ZSQ` originally. the sum of squares of values seen\n      // thus far\n      sum_squares = 0,\n          // `WT` originally. This is the number of\n      w = 0,\n          // `IV` originally\n      i4 = 0; // in several instances, you could say `Math.pow(x, 2)`\n      // instead of `x * x`, but this is slower in some browsers\n      // introduces an unnecessary concept.\n\n      for (var m = 1; m < l + 1; m++) {\n        // `III` originally\n        var lower_class_limit = l - m + 1,\n            val = data[lower_class_limit - 1]; // here we're estimating variance for each potential classing\n        // of the data, for each potential number of classes. `w`\n        // is the number of data points considered so far.\n\n        w++; // increase the current sum and sum-of-squares\n\n        sum += val;\n        sum_squares += val * val; // the variance at this point in the sequence is the difference\n        // between the sum of squares and the total x 2, over the number\n        // of samples.\n\n        variance = sum_squares - sum * sum / w;\n        i4 = lower_class_limit - 1;\n\n        if (i4 !== 0) {\n          for (j = 2; j < n_classes + 1; j++) {\n            // if adding this element to an existing class\n            // will increase its variance beyond the limit, break\n            // the class at this point, setting the lower_class_limit\n            // at this point.\n            if (variance_combinations[l][j] >= variance + variance_combinations[i4][j - 1]) {\n              lower_class_limits[l][j] = lower_class_limit;\n              variance_combinations[l][j] = variance + variance_combinations[i4][j - 1];\n            }\n          }\n        }\n      }\n\n      lower_class_limits[l][1] = 1;\n      variance_combinations[l][1] = variance;\n    } // return the two matrices. for just providing breaks, only\n    // `lower_class_limits` is needed, but variances can be useful to\n    // evaluage goodness of fit.\n\n\n    return {\n      lower_class_limits: lower_class_limits,\n      variance_combinations: variance_combinations\n    };\n  } // the second part of the jenks recipe: take the calculated matrices\n  // and derive an array of n breaks.\n\n\n  function breaks(data, lower_class_limits, n_classes) {\n    var k = data.length - 1,\n        kclass = [],\n        countNum = n_classes; // the calculation of classes will never include the upper and\n    // lower bounds, so we need to explicitly set them\n\n    kclass[n_classes] = data[data.length - 1];\n    kclass[0] = data[0]; // the lower_class_limits matrix is used as indexes into itself\n    // here: the `k` variable is reused in each iteration.\n\n    while (countNum > 1) {\n      kclass[countNum - 1] = data[lower_class_limits[k][countNum] - 2];\n      k = lower_class_limits[k][countNum] - 1;\n      countNum--;\n    }\n\n    return kclass;\n  }\n\n  if (n_classes > data.length) return null; // sort data in numerical order, since this is expected\n  // by the matrices function\n\n  data = data.slice().sort(function (a, b) {\n    return a - b;\n  }); // get our basic matrices\n\n  var matrices = getMatrices(data, n_classes),\n      // we only need lower class limits here\n  lower_class_limits = matrices.lower_class_limits; // extract n_classes out of the computed matrices\n\n  return breaks(data, lower_class_limits, n_classes);\n}",{"version":3,"sources":["src\\js\\jenks.js"],"names":["jenks","data","n_classes","getMatrices","lower_class_limits","variance_combinations","i","j","variance","length","tmp1","tmp2","push","Infinity","l","sum","sum_squares","w","i4","m","lower_class_limit","val","breaks","k","kclass","countNum","slice","sort","a","b","matrices"],"mappings":";AAAA;AACA;AACA;AACA;AACA;AACA,eAAe,SAASA,KAAT,CAAeC,IAAf,EAAqBC,SAArB,EAAgC;AAE3C;AACA;AACA,WAASC,WAAT,CAAqBF,IAArB,EAA2BC,SAA3B,EAAsC;AAElC;AACA;AACA;AACA;AACA;AACA,QAAIE,qBAAqB,EAAzB;AAAA,QACIC,wBAAwB,EAD5B;AAAA,QAEI;AACAC,KAHJ;AAAA,QAGOC,CAHP;AAAA,QAII;AACAC,eAAW,CALf,CAPkC,CAclC;;AACA,SAAKF,IAAI,CAAT,EAAYA,IAAIL,KAAKQ,MAAL,GAAc,CAA9B,EAAiCH,GAAjC,EAAsC;AAClC,UAAII,OAAO,EAAX;AAAA,UAAeC,OAAO,EAAtB;;AACA,WAAKJ,IAAI,CAAT,EAAYA,IAAIL,YAAY,CAA5B,EAA+BK,GAA/B,EAAoC;AAChCG,aAAKE,IAAL,CAAU,CAAV;AACAD,aAAKC,IAAL,CAAU,CAAV;AACH;;AACDR,yBAAmBQ,IAAnB,CAAwBF,IAAxB;AACAL,4BAAsBO,IAAtB,CAA2BD,IAA3B;AACH;;AAED,SAAKL,IAAI,CAAT,EAAYA,IAAIJ,YAAY,CAA5B,EAA+BI,GAA/B,EAAoC;AAChCF,yBAAmB,CAAnB,EAAsBE,CAAtB,IAA2B,CAA3B;AACAD,4BAAsB,CAAtB,EAAyBC,CAAzB,IAA8B,CAA9B,CAFgC,CAGhC;AACA;;AACA,WAAKC,IAAI,CAAT,EAAYA,IAAIN,KAAKQ,MAAL,GAAc,CAA9B,EAAiCF,GAAjC,EAAsC;AAClCF,8BAAsBE,CAAtB,EAAyBD,CAAzB,IAA8BO,QAA9B;AACH;AACJ;;AAED,SAAK,IAAIC,IAAI,CAAb,EAAgBA,IAAIb,KAAKQ,MAAL,GAAc,CAAlC,EAAqCK,GAArC,EAA0C;AAEtC;AACA;AACA,UAAIC,MAAM,CAAV;AAAA,UACI;AACA;AACAC,oBAAc,CAHlB;AAAA,UAII;AACAC,UAAI,CALR;AAAA,UAMI;AACAC,WAAK,CAPT,CAJsC,CAatC;AACA;AACA;;AACA,WAAK,IAAIC,IAAI,CAAb,EAAgBA,IAAIL,IAAI,CAAxB,EAA2BK,GAA3B,EAAgC;AAE5B;AACA,YAAIC,oBAAoBN,IAAIK,CAAJ,GAAQ,CAAhC;AAAA,YACIE,MAAMpB,KAAKmB,oBAAoB,CAAzB,CADV,CAH4B,CAM5B;AACA;AACA;;AACAH,YAT4B,CAW5B;;AACAF,eAAOM,GAAP;AACAL,uBAAeK,MAAMA,GAArB,CAb4B,CAe5B;AACA;AACA;;AACAb,mBAAWQ,cAAeD,MAAMA,GAAP,GAAcE,CAAvC;AAEAC,aAAKE,oBAAoB,CAAzB;;AAEA,YAAIF,OAAO,CAAX,EAAc;AACV,eAAKX,IAAI,CAAT,EAAYA,IAAIL,YAAY,CAA5B,EAA+BK,GAA/B,EAAoC;AAChC;AACA;AACA;AACA;AACA,gBAAIF,sBAAsBS,CAAtB,EAAyBP,CAAzB,KACCC,WAAWH,sBAAsBa,EAAtB,EAA0BX,IAAI,CAA9B,CADhB,EACmD;AAC/CH,iCAAmBU,CAAnB,EAAsBP,CAAtB,IAA2Ba,iBAA3B;AACAf,oCAAsBS,CAAtB,EAAyBP,CAAzB,IAA8BC,WAC1BH,sBAAsBa,EAAtB,EAA0BX,IAAI,CAA9B,CADJ;AAEH;AACJ;AACJ;AACJ;;AAEDH,yBAAmBU,CAAnB,EAAsB,CAAtB,IAA2B,CAA3B;AACAT,4BAAsBS,CAAtB,EAAyB,CAAzB,IAA8BN,QAA9B;AACH,KA3FiC,CA6FlC;AACA;AACA;;;AACA,WAAO;AACHJ,0BAAoBA,kBADjB;AAEHC,6BAAuBA;AAFpB,KAAP;AAIH,GAxG0C,CA4G3C;AACA;;;AACA,WAASiB,MAAT,CAAgBrB,IAAhB,EAAsBG,kBAAtB,EAA0CF,SAA1C,EAAqD;AAEjD,QAAIqB,IAAItB,KAAKQ,MAAL,GAAc,CAAtB;AAAA,QACIe,SAAS,EADb;AAAA,QAEIC,WAAWvB,SAFf,CAFiD,CAMjD;AACA;;AACAsB,WAAOtB,SAAP,IAAoBD,KAAKA,KAAKQ,MAAL,GAAc,CAAnB,CAApB;AACAe,WAAO,CAAP,IAAYvB,KAAK,CAAL,CAAZ,CATiD,CAWjD;AACA;;AACA,WAAOwB,WAAW,CAAlB,EAAqB;AACjBD,aAAOC,WAAW,CAAlB,IAAuBxB,KAAKG,mBAAmBmB,CAAnB,EAAsBE,QAAtB,IAAkC,CAAvC,CAAvB;AACAF,UAAInB,mBAAmBmB,CAAnB,EAAsBE,QAAtB,IAAkC,CAAtC;AACAA;AACH;;AAED,WAAOD,MAAP;AACH;;AAED,MAAItB,YAAYD,KAAKQ,MAArB,EAA6B,OAAO,IAAP,CApIc,CAsI3C;AACA;;AACAR,SAAOA,KAAKyB,KAAL,GAAaC,IAAb,CAAkB,UAAUC,CAAV,EAAaC,CAAb,EAAgB;AAAE,WAAOD,IAAIC,CAAX;AAAe,GAAnD,CAAP,CAxI2C,CA0I3C;;AACA,MAAIC,WAAW3B,YAAYF,IAAZ,EAAkBC,SAAlB,CAAf;AAAA,MACI;AACAE,uBAAqB0B,SAAS1B,kBAFlC,CA3I2C,CA+I3C;;AACA,SAAOkB,OAAOrB,IAAP,EAAaG,kBAAb,EAAiCF,SAAjC,CAAP;AAEH","sourceRoot":"C:\\Users\\yz.liu\\Desktop\\Experiment\\COVID2019","sourcesContent":["// # [Jenks natural breaks optimization](http://en.wikipedia.org/wiki/Jenks_natural_breaks_optimization)\r\n//\r\n// Implementations: [1](http://danieljlewis.org/files/2010/06/Jenks.pdf) (python),\r\n// [2](https://github.com/vvoovv/djeo-jenks/blob/master/main.js) (buggy),\r\n// [3](https://github.com/simogeo/geostats/blob/master/lib/geostats.js#L407) (works)\r\nexport default function jenks(data, n_classes) {\r\n\r\n    // Compute the matrices required for Jenks breaks. These matrices\r\n    // can be used for any classing of data with `classes <= n_classes`\r\n    function getMatrices(data, n_classes) {\r\n\r\n        // in the original implementation, these matrices are referred to\r\n        // as `LC` and `OP`\r\n        //\r\n        // * lower_class_limits (LC): optimal lower class limits\r\n        // * variance_combinations (OP): optimal variance combinations for all classes\r\n        var lower_class_limits = [],\r\n            variance_combinations = [],\r\n            // loop counters\r\n            i, j,\r\n            // the variance, as computed at each step in the calculation\r\n            variance = 0;\r\n\r\n        // Initialize and fill each matrix with zeroes\r\n        for (i = 0; i < data.length + 1; i++) {\r\n            var tmp1 = [], tmp2 = [];\r\n            for (j = 0; j < n_classes + 1; j++) {\r\n                tmp1.push(0);\r\n                tmp2.push(0);\r\n            }\r\n            lower_class_limits.push(tmp1);\r\n            variance_combinations.push(tmp2);\r\n        }\r\n\r\n        for (i = 1; i < n_classes + 1; i++) {\r\n            lower_class_limits[1][i] = 1;\r\n            variance_combinations[1][i] = 0;\r\n            // in the original implementation, 9999999 is used but\r\n            // since Javascript has `Infinity`, we use that.\r\n            for (j = 2; j < data.length + 1; j++) {\r\n                variance_combinations[j][i] = Infinity;\r\n            }\r\n        }\r\n\r\n        for (var l = 2; l < data.length + 1; l++) {\r\n\r\n            // `SZ` originally. this is the sum of the values seen thus\r\n            // far when calculating variance.\r\n            var sum = 0,\r\n                // `ZSQ` originally. the sum of squares of values seen\r\n                // thus far\r\n                sum_squares = 0,\r\n                // `WT` originally. This is the number of\r\n                w = 0,\r\n                // `IV` originally\r\n                i4 = 0;\r\n\r\n            // in several instances, you could say `Math.pow(x, 2)`\r\n            // instead of `x * x`, but this is slower in some browsers\r\n            // introduces an unnecessary concept.\r\n            for (var m = 1; m < l + 1; m++) {\r\n\r\n                // `III` originally\r\n                var lower_class_limit = l - m + 1,\r\n                    val = data[lower_class_limit - 1];\r\n\r\n                // here we're estimating variance for each potential classing\r\n                // of the data, for each potential number of classes. `w`\r\n                // is the number of data points considered so far.\r\n                w++;\r\n\r\n                // increase the current sum and sum-of-squares\r\n                sum += val;\r\n                sum_squares += val * val;\r\n\r\n                // the variance at this point in the sequence is the difference\r\n                // between the sum of squares and the total x 2, over the number\r\n                // of samples.\r\n                variance = sum_squares - (sum * sum) / w;\r\n\r\n                i4 = lower_class_limit - 1;\r\n\r\n                if (i4 !== 0) {\r\n                    for (j = 2; j < n_classes + 1; j++) {\r\n                        // if adding this element to an existing class\r\n                        // will increase its variance beyond the limit, break\r\n                        // the class at this point, setting the lower_class_limit\r\n                        // at this point.\r\n                        if (variance_combinations[l][j] >=\r\n                            (variance + variance_combinations[i4][j - 1])) {\r\n                            lower_class_limits[l][j] = lower_class_limit;\r\n                            variance_combinations[l][j] = variance +\r\n                                variance_combinations[i4][j - 1];\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n\r\n            lower_class_limits[l][1] = 1;\r\n            variance_combinations[l][1] = variance;\r\n        }\r\n\r\n        // return the two matrices. for just providing breaks, only\r\n        // `lower_class_limits` is needed, but variances can be useful to\r\n        // evaluage goodness of fit.\r\n        return {\r\n            lower_class_limits: lower_class_limits,\r\n            variance_combinations: variance_combinations\r\n        };\r\n    }\r\n\r\n\r\n\r\n    // the second part of the jenks recipe: take the calculated matrices\r\n    // and derive an array of n breaks.\r\n    function breaks(data, lower_class_limits, n_classes) {\r\n\r\n        var k = data.length - 1,\r\n            kclass = [],\r\n            countNum = n_classes;\r\n\r\n        // the calculation of classes will never include the upper and\r\n        // lower bounds, so we need to explicitly set them\r\n        kclass[n_classes] = data[data.length - 1];\r\n        kclass[0] = data[0];\r\n\r\n        // the lower_class_limits matrix is used as indexes into itself\r\n        // here: the `k` variable is reused in each iteration.\r\n        while (countNum > 1) {\r\n            kclass[countNum - 1] = data[lower_class_limits[k][countNum] - 2];\r\n            k = lower_class_limits[k][countNum] - 1;\r\n            countNum--;\r\n        }\r\n\r\n        return kclass;\r\n    }\r\n\r\n    if (n_classes > data.length) return null;\r\n\r\n    // sort data in numerical order, since this is expected\r\n    // by the matrices function\r\n    data = data.slice().sort(function (a, b) { return a - b; });\r\n\r\n    // get our basic matrices\r\n    var matrices = getMatrices(data, n_classes),\r\n        // we only need lower class limits here\r\n        lower_class_limits = matrices.lower_class_limits;\r\n\r\n    // extract n_classes out of the computed matrices\r\n    return breaks(data, lower_class_limits, n_classes);\r\n\r\n}\r\n"]}]}